{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2-4-11-Question.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktqTCGHJw-ws"
      },
      "source": [
        "# Bean Disease Classifier\n",
        "For this assignment you'll take what you've learned so far and build a classifier for bean disease. You'll be provided with training and validation data based on 224x224 pixel color images taken of bean plants in Uganda. These images show healthy bean leaves as well as 2 types of common disease: bean rust and angular leaf spots. Your job will be to build a neural network that can tell the difference between the healthy and diseased leaves.\n",
        "\n",
        "Original dataset folder: https://www.tensorflow.org/datasets/catalog/beans\n",
        "\n",
        "<img src='https://storage.googleapis.com/tfds-data/visualization/fig/beans-0.1.0.png'>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hguTKBbzeEG"
      },
      "source": [
        "We start by setting up the problem for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmnkg6vGbX1t"
      },
      "source": [
        "# Do not change this code\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njf4YhwFb6hW"
      },
      "source": [
        "# Do not change this code\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/ibeans/train.zip \\\n",
        "    -O /tmp/train.zip\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/ibeans/validation.zip \\\n",
        "    -O /tmp/validation.zip\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/ibeans/test.zip \\\n",
        "    -O /tmp/test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KscpTrSWcK1T"
      },
      "source": [
        "# Do not change this code\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/train.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "local_zip = '/tmp/validation.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "local_zip = '/tmp/test.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/test')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAPxBUgdsBGn"
      },
      "source": [
        "Now you need to define a generator to process the data we have loaded in Colab so that our model can use it for training. As we showed in the previous video you'll first have to define an ```ImageDataGenerator``` and then flow the data into it.\n",
        "\n",
        "*A hint: You don't want abnormal data!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCiSd248caB4"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      # YOUR CODE HERE #\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "      # YOUR CODE HERE #\n",
        ")\n",
        "\n",
        "TRAIN_DIRECTORY_LOCATION = # YOUR CODE HERE #\n",
        "VAL_DIRECTORY_LOCATION = # YOUR CODE HERE #\n",
        "TARGET_SIZE = # YOUR CODE HERE #\n",
        "CLASS_MODE = # YOUR CODE HERE #\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIRECTORY_LOCATION,\n",
        "    target_size = TARGET_SIZE,  \n",
        "    batch_size = 128,\n",
        "    class_mode = CLASS_MODE\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    VAL_DIRECTORY_LOCATION,\n",
        "    target_size = TARGET_SIZE,  \n",
        "    batch_size = 128,\n",
        "    class_mode = CLASS_MODE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya1DG2sVsBGo"
      },
      "source": [
        "Now its your turn to define a model to learn this data. \n",
        "\n",
        "*A hint: Like with the CIFAR-10 assignment, your model may want to learn some high level features and then classify them. This time it may help to make the model a little wider at times.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrJt6YSDcqjX"
      },
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.Sequential([\n",
        "    #YOUR CODE HERE#\n",
        "])\n",
        "\n",
        "# This will print a summary of your model when you're done!\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3suvu86sBGo"
      },
      "source": [
        "Then you'll need to pick an appropriate loss function and optimizer.\n",
        "\n",
        "*A hint: remember we are classifying again.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nST6CyvCcy-2"
      },
      "source": [
        "LOSS_FUNCTION = #YOUR CODE HERE#\n",
        "OPTIMIZER = #YOUR CODE HERE#\n",
        "\n",
        "model.compile(\n",
        "    loss = LOSS_FUNCTION,\n",
        "    optimizer = OPTIMIZER,\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKllZEAOsBGp"
      },
      "source": [
        "Finally select the number of epochs you'd like to train for and train your model!\n",
        "\n",
        "*A hint: something in the low tens is a good place to start*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3iK9LX9deu2"
      },
      "source": [
        "NUM_EPOCHS = #YOUR CODE HERE#\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator, \n",
        "      epochs = NUM_EPOCHS,\n",
        "      verbose = 1,\n",
        "      validation_data = validation_generator)\n",
        "\n",
        "# summarize history for accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.xlim([0,NUM_EPOCHS])\n",
        "plt.ylim([0.4,1.0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}